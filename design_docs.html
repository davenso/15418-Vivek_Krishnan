<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>15418 Final Project by vrkrishn</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/vrkrishn/15418-Vivek_Krishnan">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/vrkrishn/15418-Vivek_Krishnan/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/vrkrishn/15418-Vivek_Krishnan/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>Random Forest Classification on an FPGA</h1>
          <p>15418 Final Project Site by Vivek Krishnan</p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/vrkrishn">vrkrishn</a></span>
        </div>
        <a href = "index.html">Home</a> <br>
        <h5>On this page I will discuss some of the design choices for the implementation of my FPGA classification algorithm</h5> <br>
         
        <h3><span class="octicon octicon-link"></span></a> Decision Tree</h3>
        <p> <img class="img-responsive" src = "images/basic_tree.png" width = "300" align="left" style = "padding:5px;"/>
            For this implementation, I will define a decision tree as a tree with s levels. Such a tree has branch nodes, at which a sample data
            is compared to a threshold and a path accordingly taken, as well as leaf nodes at which the final result is calculated and sent to the
            analysis unit.
        </p>
        <p> Laid out in memory, the decision tree can be represented as a large array of size [(5 * 2 ^ s - 2) * sizeof(data)]. There are 2 ^ s - 1
            branch nodes which each take up 2 data slots of memory. There are also 2 ^ s leaf nodes which each take up 3 data slots of memory. Our system
            is implemented such that all trees have the same number of branch and leaf nodes such that indexing into a tree in the forest is 
            straightforeward. A possible modification to emphasize scalability would have an array of indices into the tree that represent where each tree starts; this system
            could allow for trees that don't uniformly branch out.
        </p>
        <p> The way that memory is laid out for a tree, the index of the left child of a node is simply (nodeIdx << 1) while the node index of the right
            child is simply (nodeIdx << 2 + 1).
        </p>
      
      
      
      
      
      
      <section id="main_content" class="inner">
        <h4> Branch Node </h4>
        <img src = "images/design2.png" width = "500"/>
        <p> For each branch node, the input to the module will be a sample set, an index of a node in the current decision tree, the
            current decision tree, as well as a valid bit to determine if the register values are ready for comparison. First, the memory
            controller finds the node with index (treeIdx * NODES_PER_TREE + nodeIDX) and outputs the corresponding threshold and
            sample index value. The sampIdx is used to select one of the samples from the array of sample data using a mux. The output of
            this mux is compared against the threshold calue outputed by the memory controller. The result of this comparison is added to the
            shifted nodeIdx to get the appropriate child node to traverse to.
        </p>
        <p> The data pipeline is simply a system by which the data propogates to the result registers at the same time the result of the computation
            is complete. As implementation continues, I expect to get the exact number of clock cycles so I could hard code the number of register transfers
            needed to faciltate storing the new updated values as the output. However, to make a more scalable system, I could use a series of control
            signals to manage the transfer between initial and final register states.
        </p>
      </section>
      
      <section id="main_content" class="inner">
        <h4> Leaf Node </h4>
        <img src = "images/design3.png" width = "500"/>
        <p> For each leaf node, the input to the module will be a sample set, and index of a node in the current decision tree, the
            current decision tree, as well as a valid bit to determine if the register values are ready for processing. Once again, the memory
            controller indexes into the array of tree data using the treeIdx as well as the nodeIdx. However, the output of the memory
            controller will be instead the sample index, a weight, and an offset. The appropriate sample is selected using the sampIdx by
            using a mux. However, now the sample is multiplied by the weight and added to the offset such that the final result of computation
            is [sample * weight + offset]. This result scheme allows the results of the decision tree to control the dependency of the result on
            the actual sample data. At one end, the result could be solely determined by the path take (weight = 0). In contrast, the result could
            be a factor of only the sample (offset = 0).
        </p>
        <p> The output of this module is the calculated result as well as a valid bit that determines whether or not the result is ready for
            processing by the overall analysis unit. Using this system I will be able to get a good sample estimation value from the tree and
            transmit it to the final analysis unit.
        </p>
      </section>
        
        
        
        
        
        
        
        <h3><span class="octicon octicon-link"></span></a> Summary</h3>
        <h4><b>I implemented a random forest classification system on an FPGA that can output samples at a rate of one sample per clock cycle. In addition, I made an alternate
              system that can signal and wait for memory responses from off-board memory. To analyze performance gains, I created a CPU implementation of
              the algorithm using OpenMP and compared execution cycles and power consumption.
        </b></h4>
        <h3> Background </h3>
        <p> A Random Forest is an ensemble classifier using many decision tree models. The training of this algorithm involves
            taking a subset of the sample data with replacement in order to grow decision trees that have levels directly related
            to the input variables. Random Forest Classifiers are highly accurate, scale well to large datasets, and give back 
            information about variable interaction or importance as well.
        </p>
        <p> The purpose of my project is to speedup the classification part of the random forest algorithm (as opposed to the
            growth of decision trees).
        </p>
        
        <pre class='brush: cpp'>
        // Brief overview of classification algorithm
//independent iterations
for (sample in sample_data) {
        
    sample_result = 0;
            
    //independent iterations
    for (tree in forest) {
        local_result = 0;
        current_node = tree.base_node;
                
        for (level < max_tree_depth) {
                 
            node_index = NUM_NODES_PER_TREE * treeIdx + current_node
            node_threshold = get_threshold (node_index);
            sample_var_idx = get_corresponding_var (node_index);
            sample_var_data = sample.getVar(sample_var_idx);
                 
            //If at a branching node in the tree
            if (level < max_tree_depth) {
                branchLeft = (sample_var_data < node_threshold);
                current_node = next_node (branchLeft);
                //If at a leaf node in the tree
                } else {
                    local_result = get_result (node_index);
                }
                
            }
            sample_result += local_result;
        }
            
        sample_responses[sample] = process_result (sample_result);
}
       </pre>
       <p> The classification algorithm above is parallelizable at both the tree level and the sample level. I plan to
           to make use of pipelining on the FPGA in order to maximize the parallelism I can get from both ends.
       </p>
       <p>
                The main structure in the random forest algorithm is the decision tree, where each node contains a sample index and a threshold through which
                samples can decide whether to proceed down the left branch or the right branch. For each decision tree, the input to the tree is a sample of
                data and the output is a data value determined by (weight * samp[idx] + offset) where weight, idx,and offset are determined by the leaf node 
                that the sample ends up at.
       </p>
        <h3><span class="octicon octicon-link"></span></a> Approach </h3>
        <h4><b>My current design implementation is on the <a href="design.html">design page</a></b></h4>
        <p>I targeted the Altera DE-2 FPGA boards with Cyclone IV FPGA units that are available in the labs of Hammershlag Hall. To draft my designs onto the board,
               I decided to use the Verilog HDL and synthesize on the board using Quartus Pro.
        </p>
        <p>At first glance, the random forest classification algorithm may not look like it has too much to
            gain from implementation on an FPGA or hardware device. For any given given decision tree in the forest,
            travesing each level of the tree requires only one comparison compared to one lookup of the next appropriate
            state of the tree. Therefore, the computation to communication ration is inherently low in this algorithm. 
            Each decision alsorequires that the decision in the previous level has already been made.</p>
            
            <p>In addition, machine learning algorithms have to deal with increasingly larger data sets that might not be
            able to be completely stored on one FPGA memory. While, FPGAs have very fast internal memory bandwidth, they
            have limited capacity to pass data in and out of an FPGA</p>
            
            <p>However, the algorithm is massively data parallel. The processing of a sample through each decision tree is 
            completely independen.</p>
        
        <p> It was interesting to actually design the parallel architecture components for the algorithm execution; I did not have
            to worry about mapping code to architecture and seeing unforseen compilation implications limit the parallel performance
            of my code.
        </p>
        <p>
            The only referance code I used in my solution was the modules that control the data input and output from the USB blaster that
            is provided on the board.
        </p>
        
       
             
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>

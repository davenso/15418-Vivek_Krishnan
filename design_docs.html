<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>15418 Final Project by vrkrishn</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/vrkrishn/15418-Vivek_Krishnan">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/vrkrishn/15418-Vivek_Krishnan/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/vrkrishn/15418-Vivek_Krishnan/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>Random Forest Classification on an FPGA</h1>
          <p>15418 Final Project Site by Vivek Krishnan</p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/vrkrishn">vrkrishn</a></span>
        </div>
        <a href = "index.html">Home</a> <br>
        <h5>On this page I will discuss some of the design choices for the implementation of my FPGA classification algorithm</h5> <br>
         
        <h3><span class="octicon octicon-link"></span></a> Decision Tree</h3>
        <p> <img class="img-responsive" src = "images/basic_tree.png" width = "300" align="left" style = "margin:5px;"/>
            For this implementation, I will define a decision tree as a tree with s levels. Such a tree has branch nodes, at which a sample data
            is compared to a threshold and a path accordingly taken, as well as leaf nodes at which the final result is calculated and sent to the
            analysis unit. Laid out in memory, the decision tree can be represented as a large array of size [(5 * 2 ^ s - 2) * sizeof(data)]. There are 2 ^ s - 1
            branch nodes which each take up 2 data slots of memory. There are also 2 ^ s leaf nodes which each take up 3 data slots of memory. My system
            is implemented such that all trees have the same number of branch and leaf nodes such that indexing into a tree in the forest is 
            straightforeward. A possible modification to emphasize scalability would have an array of indices into the tree that represent where each tree starts; this system
            could allow for trees that don't uniformly branch out.
        </p>
        <p> The way that memory is laid out for a tree, the index of the left child of a node is simply (nodeIdx << 1) while the node index of the right
            child is simply (nodeIdx << 2 + 1).
        </p>
        <p> The naive implementation of the tree is to create node logic for every node in the tree. However, in this setup, the amount of routing logic
            used by the tree will grow exponentially with respect to the depth of the tree. In addition, we can only perform action at one node in each level at any
            given time because of the dependencies of the tree.
        </p>
        <p><img class="img-responsive" src = "images/level_tree.png" width = "300" align="right" style = "margin:5px;"/>
          Therefore, I decided to instead represent each level of the tree as a stage and store the values for each node in an appropriate stage memory for
          each level of the tree. The SRAM memory banks on the FPGA are dual port at max so I could not achieve
          both one cycle memory access and a coagulated bank of memory. Therefore, the memory at each stage is a different memory module which is hooked up to the
          stage logic with a memory controller.
        </p>
        <p>There modifications reduce the routing logic on the FPGA tree to about linear compared to the depth of the tree. In this version of the tree, the node index
           is passed in from the top of the tree and will shift either to the right or left based on which direction the sample has to go.
        </p>
        <h3><span class="octicon octicon-link"></span></a> Tree Node Design</h3>
        <p> <img class = "img-responsive" src = "images/internal_stage.png" width = "300" align="right" style = "margin:5px;"/>
            For each internal node, the input to the module will be a sample set, an index of a node in the current decision tree, the
            current decision tree, as well as a valid bit to determine if the register values are ready for comparison, as well as the recieve lines for
            the modules that are dependent. The outputs of the module are receive lines when recieving data, an output nodeIdx, the sample for the next node
            to the right, and valid lines for both sample and nodeIdx.</p>
        <p>
            First, the memory controller finds the node with index (treeIdx * NODES_PER_TREE + nodeIDX) and outputs the corresponding threshold and
            sample index value. The sampIdx is used to select one of the samples from the array of sample data using a mux. The output of
            this mux is compared against the threshold calue outputed by the memory controller. The result of this comparison is added to the
            shifted nodeIdx to get the appropriate child node to traverse to.
        </p>
        <p> Assuming that memory access takes one cycle, the passage of a sample and node through this stage is one cycle.
        </p>
      </section>
        
        <h3><span class="octicon octicon-link"></span></a> Summary</h3>
        <h4><b>I implemented a random forest classification system on an FPGA that can output samples at a rate of one sample per clock cycle. In addition, I made an alternate
              system that can signal and wait for memory responses from off-board memory. To analyze performance gains, I created a CPU implementation of
              the algorithm using OpenMP and compared execution cycles and power consumption.
        </b></h4>
        <h3> Background </h3>
        <p> A Random Forest is an ensemble classifier using many decision tree models. The training of this algorithm involves
            taking a subset of the sample data with replacement in order to grow decision trees that have levels directly related
            to the input variables. Random Forest Classifiers are highly accurate, scale well to large datasets, and give back 
            information about variable interaction or importance as well.
        </p>
        <p> The purpose of my project is to speedup the classification part of the random forest algorithm (as opposed to the
            growth of decision trees).
        </p>
        
        <pre class='brush: cpp'>
        // Brief overview of classification algorithm
//independent iterations
for (sample in sample_data) {
        
    sample_result = 0;
            
    //independent iterations
    for (tree in forest) {
        local_result = 0;
        current_node = tree.base_node;
                
        for (level < max_tree_depth) {
                 
            node_index = NUM_NODES_PER_TREE * treeIdx + current_node
            node_threshold = get_threshold (node_index);
            sample_var_idx = get_corresponding_var (node_index);
            sample_var_data = sample.getVar(sample_var_idx);
                 
            //If at a branching node in the tree
            if (level < max_tree_depth) {
                branchLeft = (sample_var_data < node_threshold);
                current_node = next_node (branchLeft);
                //If at a leaf node in the tree
                } else {
                    local_result = get_result (node_index);
                }
                
            }
            sample_result += local_result;
        }
            
        sample_responses[sample] = process_result (sample_result);
}
       </pre>
       <p> The classification algorithm above is parallelizable at both the tree level and the sample level. I plan to
           to make use of pipelining on the FPGA in order to maximize the parallelism I can get from both ends.
       </p>
       <p>
                The main structure in the random forest algorithm is the decision tree, where each node contains a sample index and a threshold through which
                samples can decide whether to proceed down the left branch or the right branch. For each decision tree, the input to the tree is a sample of
                data and the output is a data value determined by (weight * samp[idx] + offset) where weight, idx,and offset are determined by the leaf node 
                that the sample ends up at.
       </p>
        <h3><span class="octicon octicon-link"></span></a> Approach </h3>
        <h4><b>My current design implementation is on the <a href="design.html">design page</a></b></h4>
        <p>I targeted the Altera DE-2 FPGA boards with Cyclone IV FPGA units that are available in the labs of Hammershlag Hall. To draft my designs onto the board,
               I decided to use the Verilog HDL and synthesize on the board using Quartus Pro.
        </p>
        <p>At first glance, the random forest classification algorithm may not look like it has too much to
            gain from implementation on an FPGA or hardware device. For any given given decision tree in the forest,
            travesing each level of the tree requires only one comparison compared to one lookup of the next appropriate
            state of the tree. Therefore, the computation to communication ration is inherently low in this algorithm. 
            Each decision alsorequires that the decision in the previous level has already been made.</p>
            
            <p>In addition, machine learning algorithms have to deal with increasingly larger data sets that might not be
            able to be completely stored on one FPGA memory. While, FPGAs have very fast internal memory bandwidth, they
            have limited capacity to pass data in and out of an FPGA</p>
            
            <p>However, the algorithm is massively data parallel. The processing of a sample through each decision tree is 
            completely independen.</p>
        
        <p> It was interesting to actually design the parallel architecture components for the algorithm execution; I did not have
            to worry about mapping code to architecture and seeing unforseen compilation implications limit the parallel performance
            of my code.
        </p>
        <p>
            The only referance code I used in my solution was the modules that control the data input and output from the USB blaster that
            is provided on the board.
        </p>
        
       
             
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>

<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>15418 Final Project by vrkrishn</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/vrkrishn/15418-Vivek_Krishnan">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/vrkrishn/15418-Vivek_Krishnan/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/vrkrishn/15418-Vivek_Krishnan/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>Random Forest Classification on an FPGA</h1>
          <p>15418 Final Project Site by Vivek Krishnan</p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/vrkrishn">vrkrishn</a></span>
        </div>
        <a href = "proposal.html">Proposal</a> <br>
        <a href = "checkpoint.html">Checkpoint</a><br>
        <a href = "design.html">Design Documents</a><br><br>
        <h3><span class="octicon octicon-link"></span></a> Summary</h3>
        <h4><b>I implemented a random forest classification system on an FPGA that can output samples at a rate of one sample per clock cycle. In addition, I made an alternate
              system that can signal and wait for memory responses from off-board memory. To analyze performance gains, I created a CPU implementation of
              the algorithm using OpenMP and compared execution cycles and power consumption.
        </b></h4>
        <h3> Background </h3>
        <p> A Random Forest is an ensemble classifier using many decision tree models. The training of this algorithm involves
            taking a subset of the sample data with replacement in order to grow decision trees that have levels directly related
            to the input variables. Random Forest Classifiers are highly accurate, scale well to large datasets, and give back 
            information about variable interaction or importance as well.
        </p>
        <p> The purpose of my project is to speedup the classification part of the random forest algorithm (as opposed to the
            growth of decision trees).
        </p>
        
        <pre class='brush: cpp'>
        // Brief overview of classification algorithm
//independent iterations
for (sample in sample_data) {
        
    sample_result = 0;
            
    //independent iterations
    for (tree in forest) {
        local_result = 0;
        current_node = tree.base_node;
                
        for (level < max_tree_depth) {
                 
            node_index = NUM_NODES_PER_TREE * treeIdx + current_node
            node_threshold = get_threshold (node_index);
            sample_var_idx = get_corresponding_var (node_index);
            sample_var_data = sample.getVar(sample_var_idx);
                 
            //If at a branching node in the tree
            if (level < max_tree_depth) {
                branchLeft = (sample_var_data < node_threshold);
                current_node = next_node (branchLeft);
                //If at a leaf node in the tree
                } else {
                    local_result = get_result (node_index);
                }
                
            }
            sample_result += local_result;
        }
            
        sample_responses[sample] = process_result (sample_result);
}
       </pre>
       <p> The classification algorithm above is parallelizable at both the tree level and the sample level. I plan to
           to make use of pipelining on the FPGA in order to maximize the parallelism I can get from both ends.
       </p>
       <p>
                The main structure in the random forest algorithm is the decision tree, where each node contains a sample index and a threshold through which
                samples can decide whether to proceed down the left branch or the right branch. For each decision tree, the input to the tree is a sample of
                data and the output is a data value determined by (weight * samp[idx] + offset) where weight, idx,and offset are determined by the leaf node 
                that the sample ends up at.
       </p>
        <h3><span class="octicon octicon-link"></span></a> Approach </h3>
        <h4><b>My current design implementation is on the <a href="design.html">design page</a></b></h4>
        <h4><b>I targeted the Altera DE-2 FPGA boards with Cyclone IV FPGA units that are available in the labs of Hammershlag Hall. To draft my designs onto the board,
               I decided to use the Verilog HDL and synthesize on the board using Quartus Pro.
        </b></h4>
        <h4><b>At first glance, the random forest classification algorithm may not look like it has too much to
            gain from implementation on an FPGA or hardware device. For any given given decision tree in the forest,
            travesing each level of the tree requires only one comparison compared to one lookup of the next appropriate
            state of the tree. Therefore, the computation to communication ration is inherently low in this algorithm. 
            Each decision alsorequires that the decision in the previous level has already been made. </b></h4>
            
            <h4><b>  In addition, machine learning algorithms have to deal with increasingly larger data sets that might not be
            able to be completely stored on one FPGA memory. While, FPGAs have very fast internal memory bandwidth, they
            have limited capacity to pass data in and out of an FPGA</b></h4>
            
            <h4><b>However, the algorithm is massively data parallel. The processing of a sample through each decision tree is 
            completely independen. </b></h4>
        </b></h4>
        <p> It was interesting to actually design the parallel architecture components for the algorithm execution; I did not have
            to worry about mapping code to architecture and seeing unforseen compilation implications limit the parallel performance
            of my code.
        </p>
        <p>
            The only referance code I used in my solution was the modules that control the data input and output from the USB blaster that
            is provided on the board.
        </p>
        
       
             
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>

<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="15418 Final Project : 15418 Final Project Site for Vivek Krishnan" />
    <link href="css/shCore.css" rel="stylesheet" type="text/css" />
    <link href="css/shThemeDefault.css" rel="stylesheet" type="text/css" />
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>15418 Final Project</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/vrkrishn/15418-Vivek_Krishnan">View on GitHub</a>

          <h2 id="project_title">Random Forest Classification on an FPGA</h2>
          <h3 id="project_tagline">Vivek Krishnan</h3>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/vrkrishn/15418-Vivek_Krishnan/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/vrkrishn/15418-Vivek_Krishnan/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <br><br>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h4><b>I plan to implement the Random Forest Classification Algorithm on an FPGA. I will then compare
            energy consumption and performance of the algorithm vs current CPU implementations.</b></h4>
      </section>
      
      <section id="main_content" class="inner">
       <span style = "color:blue"> Background </span>
        <p> A Random Forest is an ensemble classifier using many decision tree models. The training of this algorithm involves
            taking a subset of the sample data with replacement in order to grow decision trees that have levels directly related
            to the input variables. Random Forest Classifiers are highly accurate, scale well to large datasets, and give back 
            information about variable interaction or importance as well.
        </p>
        <p> The purpose of my project is to speedup the classification part of the random forest algorithm (as opposed to the
            growth of decision trees).
        </p>
        
        <pre class='brush: cpp'>
        // Brief overview of classification algorithm
        
        for (sample in sample_data) {
        
            sample_result = 0;
            
            for (tree in forest) {
                local_result = 0;
                current_node = tree.base_node; //possible 0
                
                for (level < max_tree_depth) {
                 
                    node_index = NUM_NODES_PER_TREE * treeIdx + current_node
                    node_threshold = get_threshold (node_index);
                    sample_var_idx = get_corresponding_var (node_index);
                    sample_var_data = sample.getVar(sample_var_idx);
                 
                    //If at a branching node in the tree
                    if (level < max_tree_depth) {
                        current_node = next_node (sample_var_data < node_threshold);
                    //If at a leaf node in the tree
                    } else {
                        local_result = get_result (node_index);
                    }
                
                }
                sample_result += local_result;
            }
            
            sample_responses[sample] = process_result (sample_result);
        }
       </pre>
       
      </section>
      
      <section id="main_content" class="inner">
      <span style = "color:blue"> Challenge </span>
        <p> At first glance, the random forest classification algorithm may not look like it has too much to
            gain from implementation on an FPGA or hardware device. For any given given decision tree in the forest,
            travesing each level of the tree requires only one comparison compared to one lookup of the next appropriate
            state of the tree. Therefore, the computation to communication ration is inherently low in this algorithm. 
            Each decision also  requires that the decision in the previous level has already been made. 
            
            Another problem is that the many decision trees spit out by the tree-growing algorithms can greatly vary in
            size and shape so any fixed width solution (such as SIMD parallelsim) can be made inefficient by the data-
            dependent nature of the method.
            
            In addition, machine learning algorithms have to deal with increasingly larger data sets that might not be
            able to be completely stored on one FPGA memory. While, FPGAs have very fast internal memory bandwidth, they
            have limited capacity to pass data around between FPGAs.
            
            However, the algorithm is massively data parallel. The processing of a sample through each decision tree is 
            completely independent
             
        </p>
      </section>
      
      <section id="main_content" class="inner">
      <span style = "color:blue"> Resources </span>
        <p> Resources </p>
      </section>
      
      <section id="main_content" class="inner">
       <span style = "color:blue"> Goals </span>
        <p> From information about current performance gains from  </p>
      </section>
      
      <section id="main_content" class="inner">
        <span style = "color:blue"> Platform Choice </span>
        <p> Heterogenous system design already is widely used in order to anticipate workloads that are more relevant to
            real world application of devices. For example, ASIC units in mobile devices today provide much of the image
            and video processing capabilities. The frequent use of these features as well as the energy and 
            performance boosts gained by using a fixed function unit outweigh the lack of functionality the ASIC unit is
            capable of performing.
        </p>
        <p> In order to fuel the trend towards computation intellegence in everyday devices, these devices must be able to
            perform basic machine learning and computer vision algorithms quickly and efficiently. Since these devices must
            constantly be aware of their surroundings, the resource drain of running these algorithms is non-trivial. Therefore,
            it makes sense to use an ASIC unit on these devices to perform common algorithms, such as the random forest
            classification.
        </p>
        <p> The FPGA is a natural testbed upon which the design for an ASIC unit can be implemented and finely tuned. Therefore,
            the platform upon which I will implement my optimized solution is the FPGA. However, for comparison I will use an
            optimized CPU solution.
        </p>
      </section>
      
      <section id="main_content" class="inner">
        <p> Schedule </p>
      </section>
      
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">15418 Final Project maintained by <a href="https://github.com/vrkrishn">vrkrishn</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>
    
  </body>
  
  <script src="js/shCore.js"></script>
  <script src="js/shBrushCpp.js"></script>
  <script>
    SyntaxHighlighter.all()
  </script>
</html>
